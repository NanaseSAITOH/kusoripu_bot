{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzEbyWC972JQ",
        "outputId": "a7859f27-41d3-4c45-fc51-674ce93aa32b"
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import glob\n",
        "import pickle\n",
        "\n",
        "import re\n",
        "import torch\n",
        "\n",
        "from pyknp import Juman\n",
        "\n",
        "def modification(word) :\n",
        "    modified = [word]\n",
        "    return modified\n",
        "\n",
        "def decomposition_file(file) :\n",
        "    jumanpp = Juman()\n",
        "    f=open(file, 'r')\n",
        "    df1 = csv.reader(f)\n",
        "    data = [ v for v in df1]\n",
        "    print('number of rows :', len(data))\n",
        "\n",
        "    parts = []\n",
        "    for i in range(len(data)) :\n",
        "        data[i][0] = data[i][0].replace(' ', '')\n",
        "        if len(data[i][0].encode('utf-8')) <= 4096 :\n",
        "            result = jumanpp.analysis(data[i][0])\n",
        "        else :\n",
        "            print(i, ' skip')\n",
        "            continue\n",
        "        for mrph in result.mrph_list():\n",
        "            parts += modification(mrph.midasi)\n",
        "        if i % 5000 == 0 :\n",
        "            print(i)\n",
        "    return parts\n",
        "\n",
        "def decomposition_sentence(sentence) :\n",
        "    jumanpp = Juman()\n",
        "    data = sentence\n",
        "    print('number of rows :', len(data))\n",
        "\n",
        "    parts = []\n",
        "    for i in range(1) :\n",
        "        data = data.replace(' ', '')\n",
        "        if len(data.encode('utf-8')) <= 4096 :\n",
        "            result = jumanpp.analysis(data)\n",
        "        else :\n",
        "            print(i, ' skip')\n",
        "            continue\n",
        "        for mrph in result.mrph_list():\n",
        "            parts += modification(mrph.midasi)\n",
        "        if i % 5000 == 0 :\n",
        "            print(i)\n",
        "    return parts\n",
        "\n",
        "# 単語ID辞書を作成する\n",
        "word2index = {}\n",
        "\n",
        "file_list=glob.glob('tweet/tweet2020-11-28.txt')\n",
        "file_list.sort()\n",
        "print(len(file_list))\n",
        "\n",
        "parts_list = []\n",
        "for j in range(len(file_list)) :\n",
        "    print(file_list[j])\n",
        "    wakati = decomposition_file(file_list[j])\n",
        "    for word in wakati:\n",
        "        if word in word2index: continue\n",
        "        word2index[word] = len(word2index)\n",
        "print(\"vocab size : \", len(word2index))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\nvocab size :  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59LP5zKpHSmV",
        "outputId": "167ce5fc-0456-4214-dc55-02825cfead75"
      },
      "source": [
        "# 文章を単語IDの系列データに変換\n",
        "# PyTorchのLSTMのインプットになるデータなので、もちろんtensor型で\n",
        "def sentence2index(sentence):\n",
        "    wakati = decomposition_sentence(sentence)\n",
        "    return torch.tensor([word2index[w] for w in wakati], dtype=torch.long)\n",
        "\n",
        "# テスト\n",
        "test = \"例のあのメニューも！ニコニコ超会議のフードコートメニュー14種類紹介（前半）\"\n",
        "print(sentence2index(test))\n",
        "# tensor([11320,     3,   449,  5483,    26,  3096,  1493,  1368,     3, 11371, 7835,   174,  8280])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of rows : 38\n",
            "0\n",
            "tensor([14066,  1239,  2490,    29,    88,  8210,  2823,  6110,     5, 10414,\n",
            "        17038,  2490,  7240,   806,  3736,   555,   116,   560])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HR4SNz16WCjT",
        "outputId": "a34b304f-756a-41f8-ed7a-6443324d9c73"
      },
      "source": [
        "import torch.nn as nn\n",
        "# 全単語数を取得\n",
        "VOCAB_SIZE = len(word2index)\n",
        "# 単語のベクトル数\n",
        "EMBEDDING_DIM = 10\n",
        "test = \"私の前に立った僕「僕はAKBの高橋を守る」\"\n",
        "# 単語IDの系列データに変換\n",
        "inputs = sentence2index(test)\n",
        "# 各単語のベクトルをまとめて取得\n",
        "embeds = nn.Embedding(VOCAB_SIZE, EMBEDDING_DIM)\n",
        "sentence_matrix = embeds(inputs)\n",
        "print(sentence_matrix.size())\n",
        "print(sentence_matrix)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of rows : 21\n",
            "0\n",
            "torch.Size([15, 10])\n",
            "tensor([[ 0.4359, -1.4191,  1.4828, -0.0416,  1.9151,  0.4492,  0.0336,  0.2881,\n",
            "          0.8882, -1.2818],\n",
            "        [ 0.4232,  1.2295, -0.3105, -0.1977,  0.7173,  2.7642, -0.1055,  0.5783,\n",
            "          0.3969, -1.0393],\n",
            "        [-0.5765, -1.0940, -1.4396,  2.5868, -0.1009,  2.5808,  1.0113, -0.7437,\n",
            "          0.5795, -0.5021],\n",
            "        [-1.8677, -0.8596,  0.4068,  0.8959,  0.0293,  0.0527, -0.0734,  0.3114,\n",
            "         -1.1921, -2.2002],\n",
            "        [ 0.8610,  0.4022,  0.4114,  2.0507, -0.9807,  0.1996, -0.7592, -0.4125,\n",
            "          0.8014,  1.0649],\n",
            "        [ 0.5940, -1.5065, -1.8374, -1.4471, -0.5120, -0.4337, -0.1018, -1.2060,\n",
            "          1.9400,  0.7027],\n",
            "        [-0.5200,  1.0667,  1.0329,  0.1118, -0.3006,  0.6896,  2.5931, -0.2750,\n",
            "          0.3796,  0.6671],\n",
            "        [ 0.5940, -1.5065, -1.8374, -1.4471, -0.5120, -0.4337, -0.1018, -1.2060,\n",
            "          1.9400,  0.7027],\n",
            "        [-0.8385, -0.6899, -0.6546, -1.0359, -0.9235,  0.8911, -0.9508,  1.6996,\n",
            "         -0.3176,  0.0437],\n",
            "        [ 0.7895,  0.7142, -0.5016, -0.7026, -0.1597,  1.6412, -0.7676, -0.7443,\n",
            "         -0.3905,  1.2079],\n",
            "        [ 0.4232,  1.2295, -0.3105, -0.1977,  0.7173,  2.7642, -0.1055,  0.5783,\n",
            "          0.3969, -1.0393],\n",
            "        [-0.4536, -0.1099, -2.3140,  0.0624,  0.1405, -1.3742,  1.7269,  0.1241,\n",
            "         -0.0213, -2.4959],\n",
            "        [-0.0804,  1.4174, -0.4000, -1.0559, -0.5729,  2.2823,  0.1481, -1.8722,\n",
            "          0.1085,  0.9027],\n",
            "        [ 2.4299, -0.5763,  0.0060, -0.1419,  0.3609, -2.1210,  1.9368,  1.1485,\n",
            "          0.8368,  0.1398],\n",
            "        [ 0.7440, -1.5108, -0.5957,  0.5058,  0.4531,  0.0460, -1.6019, -0.4679,\n",
            "          1.0371,  2.1355]], grad_fn=<EmbeddingBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}