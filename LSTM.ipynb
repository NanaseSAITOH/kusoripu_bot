{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "wzEbyWC972JQ",
        "outputId": "dd60a8e4-7679-4fb6-c947-937bd907aba0"
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import glob\n",
        "import pickle\n",
        "\n",
        "import re\n",
        "import torch\n",
        "\n",
        "from pyknp import Juman\n",
        "\n",
        "def modification(word) :\n",
        "    modified = [word]\n",
        "    return modified\n",
        "\n",
        "def decomposition(sentence) :\n",
        "    jumanpp = Juman()\n",
        "    data = sentence\n",
        "    parts = []\n",
        "    for i in range(len(data)) :\n",
        "        data= data.replace(' ', '')\n",
        "        if len(data.encode('utf-8')) <= 4096 :\n",
        "            result = jumanpp.analysis(data)\n",
        "        else :\n",
        "            print(i, ' skip')\n",
        "            continue\n",
        "        for mrph in result.mrph_list():\n",
        "            parts += modification(mrph.midasi)\n",
        "        if i % 5000 == 0 :\n",
        "            print(i)\n",
        "    return parts\n",
        "\n",
        "# テスト\n",
        "test = \"【人工知能】は「人間」の仕事を奪った\"\n",
        "print(decomposition(test))\n",
        "# ['人工', '知能', 'は', '人間', 'の', '仕事', 'を', '奪っ', 'た']\n",
        "\n",
        "# 単語ID辞書を作成する\n",
        "word2index = {}\n",
        "for title in datasets[\"title\"]:\n",
        "    wakati = make_wakati(title)\n",
        "    for word in wakati:\n",
        "        if word in word2index: continue\n",
        "        word2index[word] = len(word2index)\n",
        "print(\"vocab size : \", len(word2index))\n",
        "# vocab size :  13229\n",
        "\n",
        "# 文章を単語IDの系列データに変換\n",
        "# PyTorchのLSTMのインプットになるデータなので、もちろんtensor型で\n",
        "def sentence2index(sentence):\n",
        "    wakati = make_wakati(sentence)\n",
        "    return torch.tensor([word2index[w] for w in wakati], dtype=torch.long)\n",
        "\n",
        "# テスト\n",
        "test = \"例のあのメニューも！ニコニコ超会議のフードコートメニュー14種類紹介（前半）\"\n",
        "print(sentence2index(test))\n",
        "# tensor([11320,     3,   449,  5483,    26,  3096,  1493,  1368,     3, 11371, 7835,   174,  8280])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n['【', '人工', '知能', '】', 'は', '「', '人間', '」', 'の', '仕事', 'を', '奪った', '【', '人工', '知能', '】', 'は', '「', '人間', '」', 'の', '仕事', 'を', '奪った', '【', '人工', '知能', '】', 'は', '「', '人間', '」', 'の', '仕事', 'を', '奪った', '【', '人工', '知能', '】', 'は', '「', '人間', '」', 'の', '仕事', 'を', '奪った', '【', '人工', '知能', '】', 'は', '「', '人間', '」', 'の', '仕事', 'を', '奪った', '【', '人工', '知能', '】', 'は', '「', '人間', '」', 'の', '仕事', 'を', '奪った', '【', '人工', '知能', '】', 'は', '「', '人間', '」', 'の', '仕事', 'を', '奪った', '【', '人工', '知能', '】', 'は', '「', '人間', '」', 'の', '仕事', 'を', '奪った', '【', '人工', '知能', '】', 'は', '「', '人間', '」', 'の', '仕事', 'を', '奪った', '【', '人工', '知能', '】', 'は', '「', '人間', '」', 'の', '仕事', 'を', '奪った', '【', '人工', '知能', '】', 'は', '「', '人間', '」', 'の', '仕事', 'を', '奪った', '【', '人工', '知能', '】', 'は', '「', '人間', '」', 'の', '仕事', 'を', '奪った', '【', '人工', '知能', '】', 'は', '「', '人間', '」', 'の', '仕事', 'を', '奪った', '【', '人工', '知能', '】', 'は', '「', '人間', '」', 'の', '仕事', 'を', '奪った', '【', '人工', '知能', '】', 'は', '「', '人間', '」', 'の', '仕事', 'を', '奪った', '【', '人工', '知能', '】', 'は', '「', '人間', '」', 'の', '仕事', 'を', '奪った', '【', '人工', '知能', '】', 'は', '「', '人間', '」', 'の', '仕事', 'を', '奪った', '【', '人工', '知能', '】', 'は', '「', '人間', '」', 'の', '仕事', 'を', '奪った']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'datasets' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-2f609736d87f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# 単語ID辞書を作成する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mword2index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mwakati\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_wakati\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwakati\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'datasets' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}