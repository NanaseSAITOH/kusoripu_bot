{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PreprocessingTweet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIMj6PizjQDQ"
      },
      "source": [
        "## Jumanのインストール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d6m12rauy1W"
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import glob\n",
        "import pickle\n",
        "\n",
        "#*******************************************************************************\n",
        "#                                                                              *\n",
        "#   単語補正                                                                   *\n",
        "#                                                                              *\n",
        "#*******************************************************************************\n",
        "def modification(word) :\n",
        "    modified = [word]\n",
        "    return modified\n",
        "\n",
        "#*******************************************************************************\n",
        "#                                                                              *\n",
        "#   品詞分解                                                                   *\n",
        "#                                                                              *\n",
        "#*******************************************************************************\n",
        "def decomposition(file, jumanpp) :\n",
        "    f=open(file, 'r')\n",
        "    df1 = csv.reader(f)\n",
        "    data = [ v for v in df1]\n",
        "    print('number of rows :', len(data))\n",
        "\n",
        "    parts = []\n",
        "    for i in range(len(data)) :\n",
        "        data[i][0] = data[i][0].replace(' ', '')\n",
        "        if len(data[i][0].encode('utf-8')) <= 4096 :\n",
        "            result = jumanpp.analysis(data[i][0])\n",
        "        else :\n",
        "            print(i, ' skip')\n",
        "            continue\n",
        "        for mrph in result.mrph_list():\n",
        "            parts += modification(mrph.midasi)\n",
        "        if i % 5000 == 0 :\n",
        "            print(i)\n",
        "    return parts\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLZYWkoZuBR3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736
        },
        "outputId": "c875b9d6-0c31-4f3d-8377-cc7c66501c62"
      },
      "source": [
        "# coding: utf-8\n",
        "from __future__ import unicode_literals\n",
        "from pyknp import Juman\n",
        "jumanpp = Juman()\n",
        "file_list=glob.glob('tweet/tweet2020-11-28.txt')\n",
        "file_list.sort()\n",
        "print(len(file_list))\n",
        "\n",
        "parts_list = []\n",
        "for j in range(len(file_list)) :\n",
        "    print(file_list[j])\n",
        "    parts_list += decomposition(file_list[j], jumanpp)\n",
        "\n",
        "with open('parts_list.pickle', 'wb') as f :    \n",
        "    pickle.dump(parts_list , f)  \n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "tweet/tweet2020-11-28.txt\n",
            "number of rows : 132\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fFUlY6GkE2N",
        "tags": []
      },
      "source": [
        "# coding: utf-8\n",
        "from __future__ import unicode_literals\n",
        "import pickle\n",
        "def genarate_npy(source_csv ,list_corpus) :\n",
        "    with codecs.open(source_csv, \"rb\") as f :\n",
        "        df2 = pickle.load(f)\n",
        "\n",
        "        mat = [ line for line in df2]\n",
        "        j=0\n",
        "        #補正\n",
        "        for i in range(0,len(mat)):\n",
        "            if len(mat[i]) !=  0 :\n",
        "                if mat[i] != '' :\n",
        "\n",
        "                    if mat[i] != '@' and mat[i] != 'EOS' and mat[i] != ':' and mat[i] != '\\\\' :\n",
        "                        if mat[i] == 'REQ' and mat[i+1] == ':' : #デリミタ「REQ:」対応\n",
        "                            list_corpus.append('REQREQ')\n",
        "                        elif mat[i] == 'RES' and mat[i+1] == ':' : #デリミタ「RES:」対応\n",
        "                            list_corpus.append('RESRES')\n",
        "                        else :\n",
        "                            list_corpus.append(mat[i])\n",
        "                        if i % 1000000 == 0 :\n",
        "                            print(i,list_corpus[j])\n",
        "                        j += 1\n",
        "    print(len(list_corpus))\n",
        "    del mat\n",
        "    return \n",
        "\n",
        "#**********************************************************************************\n",
        "#                                                                                 *\n",
        "#  メイン処理                                                                     *\n",
        "#                                                                                 *\n",
        "#**********************************************************************************\n",
        "if __name__ == '__main__':\n",
        "    import numpy as np\n",
        "    import csv\n",
        "    import glob\n",
        "    import re\n",
        "    import pickle\n",
        "    import codecs\n",
        "\n",
        "    file_list = glob.glob('juman/*')\n",
        "    print(len(file_list))\n",
        "\n",
        "    n_words = 0\n",
        "    for j in range(0,len(file_list)) :\n",
        "\n",
        "        print(file_list[j])\n",
        "        generated_list=[]\n",
        "        genarate_npy(file_list[j],generated_list)\n",
        "        #コーパスリストセーブ\n",
        "        with open('list_corpus/list_corpus'+str(j)+'.pickle', 'wb') as g :\n",
        "            pickle.dump(generated_list , g)\n",
        "        n_words += len(generated_list)\n",
        "        print(n_words)\n",
        "        del generated_list\n"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\njuman/parts_list.pickle\n0 REQREQ\n2863\n2863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gm8Fkjakkzfi"
      },
      "source": [
        "# coding: utf-8\n",
        "def generate_mat() :\n",
        "\n",
        "    file_list = glob.glob('list_corpus/*')\n",
        "    print('ファイル数 =',len(file_list))\n",
        "    mat=[]\n",
        "    for i in range (0,len(file_list)) :\n",
        "        with open(file_list[i],'rb') as f :\n",
        "            generated_list=pickle.load(f)         #生成リストロード\n",
        "            mat.extend(generated_list)\n",
        "            print(i)\n",
        "            del generated_list\n",
        "\n",
        "\n",
        "    mat.append('REQREQ')\n",
        "\n",
        "    print(\"len(mat)\",len(mat))\n",
        "    \n",
        "    words = sorted(list(set(mat)))\n",
        "    cnt = np.zeros(len(words))\n",
        "\n",
        "    print('total words:', len(words))\n",
        "    word_indices = dict((w, i) for i, w in enumerate(words))    #単語をキーにインデックス検索\n",
        "    indices_word = dict((i, w) for i, w in enumerate(words))    #インデックスをキーに単語を検索\n",
        "\n",
        "    #単語の出現数をカウント\n",
        "    for j in range (0,len(mat)):\n",
        "        cnt[word_indices[mat[j]]] += 1\n",
        "\n",
        "    #出現頻度の少ない単語を「UNK」で置き換え\n",
        "    words_unk = []                                #未知語一覧\n",
        "\n",
        "    for k in range(0,len(words)):\n",
        "        if cnt[k] <= 0 :\n",
        "            words_unk.append(words[k])\n",
        "            words[k] = 'UNK'\n",
        "\n",
        "    print('words_unk:',len(words_unk))                   # words_unkはunkに変換された単語のリスト\n",
        "\n",
        "    #低頻度単語をUNKに置き換えたので、辞書作り直し\n",
        "    words = list(set(words))\n",
        "    words.append('\\t')                                   #０パディング対策。インデックス０用キャラクタを追加\n",
        "    words = sorted(words)\n",
        "    print('new total words:', len(words))\n",
        "    word_indices = dict((w, i) for i, w in enumerate(words))    #単語をキーにインデックス検索\n",
        "    indices_word = dict((i, w) for i, w in enumerate(words))    #インデックスをキーに単語を検索\n",
        "\n",
        "    #単語インデックス配列作成\n",
        "    mat_urtext = np.zeros((len(mat),1),dtype=int)\n",
        "    for i in range(0,len(mat)):\n",
        "        if mat[i] in word_indices :           #出現頻度の低い単語のインデックスをunkのそれに置き換え\n",
        "            mat_urtext[i,0] = word_indices[mat[i]]\n",
        "        else:\n",
        "            mat_urtext[i,0] = word_indices['UNK']\n",
        "\n",
        "    print(mat_urtext.shape)\n",
        "\n",
        "    #作成した辞書をセーブ\n",
        "    with open('word_indices.pickle', 'wb') as f :\n",
        "        pickle.dump(word_indices , f)\n",
        "\n",
        "    with open('indices_word.pickle', 'wb') as g :\n",
        "        pickle.dump(indices_word , g)\n",
        "\n",
        "    #単語ファイルセーブ\n",
        "    with open('words.pickle', 'wb') as h :\n",
        "        pickle.dump(words , h)\n",
        "        print(len(words))\n",
        "\n",
        "    #コーパスセーブ\n",
        "    with open('mat_urtext.pickle', 'wb') as ff :\n",
        "        pickle.dump(mat_urtext , ff)    \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import numpy as np\n",
        "    import pickle\n",
        "    import glob\n",
        "\n",
        "    generate_mat()\n"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ファイル数 = 1\n0\nlen(mat) 2864\ntotal words: 1095\nwords_unk: 0\nnew total words: 1096\n(2864, 1)\n1096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOZprUR5qyFw"
      },
      "source": [
        "with open('words.pickle', 'rb') as f :\n",
        "        words=pickle.load(f)    \n",
        "        print(len(words),words)\n",
        "\n",
        "    #作成した辞書をロード\n",
        "with open('word_indices.pickle', 'rb') as f :\n",
        "    word_indices=pickle.load(f)\n",
        "\n",
        "with open('indices_word.pickle', 'rb') as g :\n",
        "    indices_word = pickle.load(g)\n",
        "\n",
        "    #コーパスロード\n",
        "with open('mat_urtext.pickle', 'rb') as ff :\n",
        "    mat_urtext = pickle.load(ff)  "
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1096 ['\\t', '!!', '%', '(', ')', '.5', '.\\\\', '/.', '0', '0310', '1', '10', '100', '2', '27', '3', '4', '5643648175', '6', '9', 'ADA', 'BGM', 'FF', 'GoTo', 'HP', 'M', 'NHK', 'REQREQ', 'RESRES', 'S', 'SmartNews', 'Yeaaaaahhhhhhhhh', 'You', 'YouTube', '^', 'anima', 'code', 'nhk', 'w', 'ww', 'www', 'wwww', '~', '×', 'Φ', 'ω', '…', '……', '①', '②', '③', '▼', '◎', '♡', '♪', '\\u3000', '、', '。', '「', '」', '【', '】', '〜〜', 'あ', 'あがって', 'あけて', 'あって', 'あと', 'あなた', 'あの', 'あまり', 'あめ', 'あり', 'ありがとう', 'ある', 'あれまぁ', 'あんた', 'あー', 'い', 'いい', 'いう', 'いき', 'いし', 'いそう', 'いた', 'いって', 'いつ', 'いつまでも', 'いつも', 'いな', 'いはい', 'いやー', 'いらっと', 'いる', 'う', 'うまい', 'うんち', 'え', 'ええ', 'お', 'おいて', 'おじさん', 'おったら', 'おつ', 'おばさん', 'おら', 'お出かけ', 'お前', 'お構い', 'お陰', 'か', 'かけて', 'かして', 'かず', 'かな', 'かなり', 'かに', 'から', 'かわ', 'かわいい', 'かわいいー', 'かわいそう', 'が', 'がっかり', 'きた', 'きて', 'きめて', 'きれいで', 'く', 'くそ', 'ください', 'くらい', 'くる', 'くれて', 'くれる', 'くん', 'けぇ', 'けど', 'けん', 'こ', 'こい', 'こいつ', 'ここ', 'こじらせ', 'こそ', 'こと', 'この', 'こま', 'これ', 'こんな', 'こんにちはー', 'ご', 'ございました', 'ございます', 'ごめん', 'ごろ', 'ご存知', 'さ', 'さあさあ', 'さん', 'ざ', 'ざる', 'し', 'しか', 'しかった', 'した', 'したら', 'したわ', 'しちゃ', 'しっかり', 'して', 'しゃ', 'しよう', 'しる', 'しろ', 'じゃ', 'じゃけん', 'じゃどう', 'す', 'すき', 'すぎて', 'すぎる', 'すみ', 'すら', 'する', 'ず', 'ずらい', 'せ', 'せちゃ', 'せて', 'せよ', 'ぜ', 'そ', 'そう', 'そういう', 'そうだ', 'そうな', 'そこ', 'そして', 'その', 'その他', 'その後', 'そもそも', 'それ', 'それとも', 'そんな', 'た', 'たい', 'たかった', 'たから', 'たし', 'たち', 'ため', 'だ', 'だけ', 'だしたら', 'だった', 'だろ', 'だろう', 'ち', 'ちっちゃくて', 'ちなみ', 'ちゃう', 'ちゃん', 'ちゃんと', 'ちょっと', 'ちらっと', 'っ', 'った', 'って', 'っぷり', 'つ', 'つか', 'つけて', 'つな', 'つまらない', 'つまり', 'づいて', 'て', 'てめー', 'で', 'であって', 'でき', 'できて', 'できる', 'でした', 'でしょ', 'でしょう', 'です', 'でっせ', 'でも', 'と', 'といて', 'ときめく', 'とっくに', 'とっとと', 'とても', 'とりあえず', 'とる', 'どう', 'どっち', 'どん', 'な', 'な〜', 'なぁ', 'なあ', 'ない', 'なかった', 'ながら', 'なく', 'なくて', 'なけりゃ', 'なっ', 'なった', 'なって', 'など', 'なな', 'なのに', 'なら', 'なり', 'なる', 'なん', 'なんか', 'なんだ', 'なんて', 'なんで', 'なんでも', 'に', 'にて', 'にゃ', 'ね', 'ねぇ', 'ねばねば', 'ねん', 'ねー', 'の', 'のう', 'のだ', 'ので', 'のでしょう', 'のです', 'のに', 'は', 'はずです', 'はずれ', 'ばち', 'ぱん', 'ひど', 'ふとした', 'ふわふわ', 'ぶり', 'へん', 'ぺで', 'ほ', 'ほしい', 'ほとんど', 'ほど', 'ほり', 'ほん', 'ま', 'まあ', 'まお', 'まさしく', 'ました', 'ましたー', 'ましょう', 'ます', 'ませ', 'また', 'まったく', 'まつ', 'まで', 'み', 'みた', 'みたいな', 'みて', 'めちゃくちゃ', 'めちゃくちゃに', 'めっしー', 'も', 'もう', 'もし', 'もって', 'もの', 'もはや', 'もん', 'や', 'やって', 'やつ', 'やめ', 'やら', 'やる', 'やれ', 'やん', 'よ', 'よ〜', 'よう', 'ように', 'よく', 'よし', 'よしのり', 'よっ', 'より', 'よわー', 'ら', 'られ', 'られて', 'られる', 'らん', 'りょうさん', 'りん', 'りんと', 'る', 'れ', 'れた', 'れて', 'れる', 'ろ', 'わ', 'わか', 'わかった', 'わかって', 'わから', 'わかり', 'わかる', 'わけない', 'わざわざ', 'を', 'ん', 'んだ', 'んだろう', 'んで', 'んです', 'んな', 'んや', 'アウト', 'アカウント', 'アキ', 'アナタ', 'アメリカ', 'アリスギア', 'アレ', 'アレです', 'ィ', 'イベント', 'イージスアショア', 'エピソード', 'エヴァ', 'エース', 'エール', 'カニヨイ', 'カフェラテ', 'ガン', 'ガンタンク', 'ガンダム', 'キャラ', 'ギア', 'クソ', 'クソリプ', 'クル', 'クーポン', 'ケインズ', 'コロナ', 'コロニーレーザー', 'ゴミ', 'ゴミカス', 'サザン', 'シンジ', 'シージ', 'ジム', 'ジャケット', 'スタイル', 'スタバ', 'ストレス', 'スーツ', 'タイミング', 'タメ', 'タメクソリプ', 'ダイハ', 'ダム', 'ダメだ', 'チャレンジ', 'チート', 'チーム', 'ツイート', 'ツッコミ', 'デザイン', 'デメリット', 'データ', 'トモ', 'トレ', 'トレーニング', 'ド', 'ドキドキ', 'ドラエール', 'ドラマ', 'ドルフィン', 'ナンセンス', 'ニュージー', 'ニュース', 'ヌーボー', 'ネタ', 'ネッ', 'ハチャメチャに', 'ハマって', 'ハンコ', 'バカ', 'パソコン', 'パニック', 'パン', 'パンダ', 'フライト', 'フライング', 'フレンド', 'ブルー', 'ブロック', 'ホーガン', 'ボジョレーヌーボー', 'ポイント', 'マジで', 'マスク', 'マップ', 'マラソン', 'メリット', 'メンバー', 'モノ', 'モビルスーツ', 'ヤバい', 'ユクシー', 'ライブ', 'ランキング', 'ランド', 'リスク', 'リスト', 'リストラ', 'リスニング', 'リプ', 'リプトン', 'リュック', 'レベル', 'ロゴ', 'ワタシ', '・', 'ー', '一', '一斉', '一番', '一般', '一郎', '上がら', '上がり', '上げ', '下げ', '下さい', '下方', '下旬', '下落', '不安', '不幸', '不当な', '不況', '不能', '与党', '中', '中国', '中曽根', '主張', '主義', '乗船', '乙', '乳児', '予定', '予防', '事', '事前', '事態', '二度と', '二階', '亞', '交流', '京', '人', '人口', '人形', '人間', '今', '今回', '今日', '他の', '付き合い', '付き合って', '付け', '以', '以上', '件', '任せ', '企業', '休み', '休校', '休業', '会い', '会う', '会え', '伝え', '位', '低', '低い', '低下', '低迷', '住んで', '何', '何で', '何も', '何故', '何？', '作った', '作ら', '作戦', '作業', '使い', '使う', '使用', '便所', '俺', '倒産', '偉', '健康な', '傷つく', '僕', '優し', '元', '元気', '先生', '先輩', '入れよう', '入稿', '全く', '全て', '全然', '公園', '公式', '公開', '共産党', '内容', '内部', '再', '写真', '冬', '冷蔵', '処刑', '出', '出さ', '出して', '出せば', '出よう', '出る', '出来', '出来て', '出来る', '出生', '出産', '分', '分から', '分かり', '分配', '切る', '切れば', '切れる', '刺し身', '刺身', '前', '割増', '労働', '勝手に', '匂わ', '化', '単純に', '厨二', '参加', '参考', '友達', '反', '反省', '収まる', '収録', '取り', '取り敢えず', '受信', '可', '可愛い', '可能', '右', '合い', '合わせて', '合戦', '同', '同じです', '名前', '吐か', '向けて', '向上', '君', '否', '周り', '呼ば', '呼び', '呼んで', '命', '哺乳', '喋って', '喋れ', '回', '回ら', '回復', '回答', '回頭', '国', '国民', '圧', '圧倒', '地味に', '垂れ流す', '基', '基本', '基礎', '埼玉', '報告', '場違い', '塊', '増', '増える', '売る', '夏', '外', '外務', '多い', '多く', '大', '大丈夫です', '大変', '大臣', '太郎', '夫婦', '失礼', '女', '女性', '奴', '好き', '好評', '姉さん', '姐さん', '嫌な', '嬉しい', '嬉しかった', '季節', '孫', '実家', '実質', '実際', '宣言', '容易に', '寒い', '対して', '小林', '少し', '就業', '崇拝', '川口', '差し替えて', '市場', '帰って', '帰り', '幅', '平均', '平城', '年', '年越し', '年齢', '庫', '庭', '康隆', '廃止', '引き', '引っ掛かり', '強い', '強く', '当', '当然', '彩', '影響', '後', '後輩', '得', '得た', '復刻', '心中', '心臓', '忖度', '応募', '思い', '思う', '思った', '思って', '思わ', '性', '恥', '息子', '悪い', '悪く', '悲しく', '悲しみ', '情報', '意味', '意見', '愛', '感じ', '感じて', '感情', '感染', '懐かし', '打ち切って', '扱い', '批判', '投資', '抜けて', '押し付け', '押し付ける', '拒否', '拗', '拡がった', '持ち', '指摘', '振り', '掛けた', '推し', '推測', '揃い', '提案', '撤回', '撮る', '操り', '支払い', '支持', '放送', '教え', '数', '整理', '敵', '料', '方', '方法', '既に', '日', '明日', '明確な', '春', '是非', '昼', '時', '時点', '暖かく', '暴言', '更に', '書いて', '書け', '最強', '最後に', '最近', '月', '有名な', '服装', '朝', '本', '本当に', '枠', '楽', '楽しみに', '楽しんで', '構', '様', '様子', '機嫌', '欲', '歓迎', '止め', '正論', '武装', '歪む', '死ぬ', '死んじゃ', '死んだ', '残念', '殺意', '殿', '母', '毒', '民営', '気', '気力', '気持ち', '決定', '河野', '泡', '洋平', '消えちゃ', '深める', '減った', '減らし', '潰して', '点', '無', '無い', '無能', '無責任だ', '無量大数', '焼きそば', '状態', '状況', '率', '現行', '理解', '瓶', '生', '生えて', '生える', '生まれ', '生産', '用', '用件', '申し訳ない', '男女', '男性', '画面', '留学', '疑い', '疾患', '病', '病んで', '痛い', '痛む', '発', '発揮', '発散', '的な', '的に', '的外れです', '皆', '監修', '目くそ', '目撃', '相応しく', '着信', '睡眠', '知ら', '知れ', '破綻', '硬直', '社長', '票', '私', '秋', '秒間', '突然の', '笑', '筈', '答えて', '簡単に', '糖尿', '糸', '納得', '納豆', '終了', '組み入れ', '経済', '結', '結局', '結果', '絡んで', '緊急', '総数', '総理', '置いた', '美しい', '群', '考え', '考えて', '者', '耐性', '聞か', '聞こえ', '聞こえた', '聴', '職員', '肩', '胸', '能', '脳', '腹', '腹痛', '自ら', '自体', '自分', '自宅', '自己', '自殺', '自粛', '自身', '良き', '良く', '良ければ', '英語', '茂木', '茶', '草', '菅', '葡萄', '薬', '行い', '補える', '要', '要請', '見', '見つかり', '見て', '覚醒', '親', '観客', '観点', '解いた', '解散', '解雇', '言う', '言って', '言わ', '計算', '記', '記念', '記録', '設定', '訳', '証', '評価', '試作', '試合', '話', '話して', '語る', '読んで', '読了', '誰', '課長', '調べたら', '談話', '論破', '諸々', '貴', '買って', '賃金', '赤ちゃん', '起こさ', '起こって', '超えて', '足', '軽はずみに', '辛辣', '辞め', '迎える', '返し', '返信', '迷惑です', '送', '送ら', '送る', '逃れ', '連邦', '逮捕', '進ま', '運命', '違う', '適', '適当に', '選ぶ', '選択', '遺体', '遺棄', '郵政', '配信', '配布', '酔って', '金', '鉄', '長い', '開く', '開催', '開発', '間違い', '間違った', '関わる', '関係', '阪', '除く', '障害', '隠せ', '電話', '面', '音', '頂く', '頭', '顕示', '飛ばして', '食べ', '食事', '飲ま', '飲んだら', '馘', '馬鹿', '驚き', '高い', '高橋', '高齢', '鬱病', '️', '！', '＃', '（', '７', '＝', '？', '＾', '～と', 'ｯ', 'ｺ', 'ｿ', 'ﾆ', 'ﾎ', 'ﾞ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}